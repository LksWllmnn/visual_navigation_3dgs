{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9701,
     "status": "ok",
     "timestamp": 1732273640724,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "ije14-0tGIlm",
    "outputId": "4416dbc5-db7d-4e43-c88c-b65ae8804083"
   },
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "#!pip install torch torchvision pycocotools\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732273640724,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "6kuz1KNbGLPL"
   },
   "outputs": [],
   "source": [
    "# Define the color-to-ID mapping\n",
    "COLOR_TO_ID = {\n",
    "    (0, 0, 255, 255): 0,    # A-Building\n",
    "    (0, 255, 0, 255): 1,    # B-Building\n",
    "    (255, 0, 0, 255): 2,    # C-Building\n",
    "    (255, 255, 255, 255): 3,  # E-Building\n",
    "    (255, 235, 4, 255): 4,  # F-Building\n",
    "    (128, 128, 128, 255): 5, # G-Building\n",
    "    (255, 32, 98, 255): 6,  # H-Building\n",
    "    (255, 25, 171, 255): 7, # I-Building\n",
    "    (93, 71, 255, 255): 8,  # L-Building\n",
    "    (255, 73, 101, 255): 9, # M-Building\n",
    "    (145, 255, 114, 255): 10, # N-Building\n",
    "    (153, 168, 255, 255): 11, # O-Building\n",
    "    (64, 0, 75, 255): 12,    # R-Building\n",
    "    (18, 178, 0, 255): 13,   # Z-Building\n",
    "    (255, 169, 0, 255): 14,  # Other\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732273640724,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "lY-6KSbcGObk"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Fortschrittsbalken hinzufügen\n",
    "\n",
    "class BuildingSegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # Liste aller Sequenzen abrufen\n",
    "        self.sequences = sorted(os.listdir(root))\n",
    "        self.imgs = []\n",
    "        self.masks = []\n",
    "\n",
    "        print(\"Lade Sequenzen...\")\n",
    "        # Durch alle Sequenzen iterieren und Bilder/Masks sammeln\n",
    "        for seq in tqdm(self.sequences, desc=\"Fortschritt\", unit=\"seq\"):\n",
    "            seq_path = os.path.join(root, seq)\n",
    "            img_file = os.path.join(seq_path, \"step0.camera.png\")\n",
    "            mask_file = os.path.join(seq_path, \"step0.camera.semantic segmentation.png\")\n",
    "            if os.path.exists(img_file) and os.path.exists(mask_file):\n",
    "                self.imgs.append(img_file)\n",
    "                self.masks.append(mask_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and mask\n",
    "        img_path = self.imgs[idx]\n",
    "        mask_path = self.masks[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"RGBA\")\n",
    "\n",
    "        # Convert mask to class IDs\n",
    "        mask_np = np.array(mask)\n",
    "        instance_mask = np.zeros(mask_np.shape[:2], dtype=np.int64)\n",
    "        for color, class_id in COLOR_TO_ID.items():\n",
    "            instance_mask[np.all(mask_np == np.array(color), axis=-1)] = class_id\n",
    "\n",
    "        # Get unique class IDs and generate binary masks\n",
    "        obj_ids = np.unique(instance_mask)\n",
    "        obj_ids = obj_ids[obj_ids > 0]  # Exclude background (0)\n",
    "        masks = instance_mask == obj_ids[:, None, None]\n",
    "\n",
    "        # Compute bounding boxes\n",
    "        boxes = []\n",
    "        for i in range(len(obj_ids)):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # Convert to tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(obj_ids, dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        if len(boxes) > 0:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        else:\n",
    "            area = torch.tensor([0.0])  # Falls keine Boxen existieren, setze area auf 0\n",
    "        iscrowd = torch.zeros((len(obj_ids),), dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd,\n",
    "        }\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732273640724,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "t6NtuqZ_GRAq"
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431964,
     "status": "ok",
     "timestamp": 1732274072684,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "_5URjPsVGWoS",
    "outputId": "51c99e3e-fb5b-4427-b0b6-7a113dfa39a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Sequenzen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fortschritt: 100%|██████████| 10005/10005 [00:01<00:00, 6766.94seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Sequenzen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fortschritt: 100%|██████████| 10005/10005 [00:01<00:00, 8086.19seq/s]\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "\n",
    "# Load the dataset\n",
    "root_dir = \"C:/Users/Lukas/AppData/LocalLow/DefaultCompany/Fuwa_HDRP/solo_1/\"  # Replace with your dataset directory\n",
    "dataset = BuildingSegmentationDataset(root=root_dir, transforms=get_transform(train=True))\n",
    "dataset_test = BuildingSegmentationDataset(root=root_dir, transforms=get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1732274072684,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "_kdclZlTGYk-"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])  # Last 50 for testing\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732274072684,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "dAUt46SPGZ8o",
    "outputId": "17d935c5-c2f1-4f60-994e-56f68695d4af"
   },
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: tuple(zip(*x)))\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "                                               collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732274072685,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "5ixmjetCGbop"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained Mask R-CNN model\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3370,
     "status": "ok",
     "timestamp": 1732274076050,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "WmsTqRWjGdip",
    "outputId": "e91fd865-487f-48c4-d820-3efb468bac58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thesis\\visual_navigation_3dgs\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Thesis\\visual_navigation_3dgs\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to C:\\Users\\Lukas/.cache\\torch\\hub\\checkpoints\\maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "num_classes = len(COLOR_TO_ID) + 1  # 15 classes (0-14) + background\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "model.to(device)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 420035,
     "status": "error",
     "timestamp": 1732274496082,
     "user": {
      "displayName": "Lukas W",
      "userId": "03408245159808875042"
     },
     "user_tz": -60
    },
    "id": "inIIgKXzF1rv",
    "outputId": "91fe2396-dd05-4119-a859-035a101842d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                                          | 0/4976 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# # Training and evaluation utilities\n",
    "# from engine import train_one_epoch, evaluate\n",
    "# import utils\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "#     lr_scheduler.step()\n",
    "#     evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(model.state_dict(), \"mask_rcnn_finetuned.pth\")\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simple training loop\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for images, targets in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100):\n",
    "        # Move images and targets to the device (GPU)\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        # Total loss\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss periodically\n",
    "        if i % print_freq == 0:\n",
    "            print(f\"Epoch {epoch+1}, Iteration {i}, Loss: {losses.item()}\")\n",
    "        i += 1\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for images, targets in tqdm(data_loader, desc=\"Evaluating\", ncols=100):\n",
    "        # Move images and targets to the device (GPU)\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Perform evaluation\n",
    "        with torch.no_grad():\n",
    "            prediction = model(images)\n",
    "\n",
    "        # Collect results (e.g., use COCO evaluation here)\n",
    "        results.append(prediction)\n",
    "\n",
    "    # Return the evaluation results (you can modify this part to use COCO metrics, etc.)\n",
    "    return results\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN3abNmAy234I9PGmzLdolZ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
